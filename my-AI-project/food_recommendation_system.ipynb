{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3fc0184-3aae-44ba-b5d3-cf202ac800fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 16:20:02.532 No runtime found, using MemoryCacheStorageManager\n",
      "2025-08-14 16:20:02.541 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.544 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.546 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.549 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.552 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.555 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.557 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.560 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.562 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.566 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.569 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.571 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.574 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.578 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.584 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.588 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.591 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.597 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.600 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.603 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.606 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.609 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.620 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.623 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.627 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.638 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.646 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.651 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.653 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.655 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.659 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.664 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.667 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-14 16:20:02.669 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"df\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:469\u001b[39m, in \u001b[36mSessionState.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem(widget_id, key)\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:517\u001b[39m, in \u001b[36mSessionState._getitem\u001b[39m\u001b[34m(self, widget_id, user_key)\u001b[39m\n\u001b[32m    516\u001b[39m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state_proxy.py:130\u001b[39m, in \u001b[36mSessionStateProxy.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state_proxy.py:101\u001b[39m, in \u001b[36mSessionStateProxy.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    100\u001b[39m require_valid_user_key(key)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m get_session_state()[key]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\streamlit\\runtime\\state\\safe_session_state.py:104\u001b[39m, in \u001b[36mSafeSessionState.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state[key]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state.py:471\u001b[39m, in \u001b[36mSessionState.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[31mKeyError\u001b[39m: 'st.session_state has no key \"df\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 174\u001b[39m\n\u001b[32m    171\u001b[39m         st.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to load dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    172\u001b[39m         st.stop()\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m df = st.session_state.df\n\u001b[32m    175\u001b[39m filters = st.session_state.filters\n\u001b[32m    176\u001b[39m title_col = st.session_state.title_col\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\streamlit\\runtime\\state\\session_state_proxy.py:132\u001b[39m, in \u001b[36mSessionStateProxy.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[31mAttributeError\u001b[39m: st.session_state has no attribute \"df\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import streamlit as st\n",
    "\n",
    "# ------------------------------\n",
    "# Helpers\n",
    "# ------------------------------\n",
    "def normalize_text(s: str) -> str:\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = str(s).lower()\n",
    "    # keep letters, numbers, commas and spaces\n",
    "    s = re.sub(r\"[^a-z0-9,+&/()' -]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def coalesce_cols(df, colnames):\n",
    "    for c in colnames:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "@st.cache_data(show_spinner=False)\n",
    "def load_dataframe(path_or_buffer):\n",
    "    if isinstance(path_or_buffer, str):\n",
    "        df = pd.read_csv(path_or_buffer)\n",
    "    else:\n",
    "        df = pd.read_csv(path_or_buffer)\n",
    "    # standardize column names\n",
    "    df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def build_corpus(df):\n",
    "    # pick best-available columns for textual features\n",
    "    name_col = coalesce_cols(df, [\"name\", \"dishname\", \"title\", \"recipe_name\"])\n",
    "    ing_col  = coalesce_cols(df, [\"ingredients\", \"ingredient\", \"ingr\", \"recipe_ingredients\"])\n",
    "    course_col = coalesce_cols(df, [\"course\", \"meal_type\", \"category\"])\n",
    "    diet_col = coalesce_cols(df, [\"diet\", \"veg_non_veg\", \"veg_nonveg\"])\n",
    "    flavor_col = coalesce_cols(df, [\"flavor_profile\", \"flavor\", \"taste\"])\n",
    "    state_col = coalesce_cols(df, [\"state\", \"origin_state\"])\n",
    "    region_col = coalesce_cols(df, [\"region\"])\n",
    "    instructions_col = coalesce_cols(df, [\"instructions\", \"steps\", \"method\", \"directions\"])\n",
    "\n",
    "    usable_cols = [c for c in [name_col, ing_col, course_col, diet_col, flavor_col, state_col, region_col, instructions_col] if c]\n",
    "\n",
    "    if not usable_cols:\n",
    "        raise ValueError(\"No textual columns found. Expected any of: name, ingredients, course, diet, flavor_profile, state, region, instructions.\")\n",
    "\n",
    "    # create a combined text field\n",
    "    def row_text(row):\n",
    "        parts = []\n",
    "        if name_col: parts.append(str(row[name_col]))\n",
    "        if ing_col: parts.append(str(row[ing_col]))\n",
    "        if course_col: parts.append(str(row[course_col]))\n",
    "        if diet_col: parts.append(str(row[diet_col]))\n",
    "        if flavor_col: parts.append(str(row[flavor_col]))\n",
    "        if state_col: parts.append(str(row[state_col]))\n",
    "        if region_col: parts.append(str(row[region_col]))\n",
    "        if instructions_col: parts.append(str(row[instructions_col])[:400])  # cap to reduce noise\n",
    "        return normalize_text(\" , \".join(parts))\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"__text__\"] = df.apply(row_text, axis=1)\n",
    "\n",
    "    # basic filters list\n",
    "    filters = {}\n",
    "    if course_col: filters[\"course\"] = course_col\n",
    "    if diet_col: filters[\"diet\"] = diet_col\n",
    "    if flavor_col: filters[\"flavor_profile\"] = flavor_col\n",
    "    if state_col: filters[\"state\"] = state_col\n",
    "    if region_col: filters[\"region\"] = region_col\n",
    "\n",
    "    # best title column\n",
    "    title_col = name_col if name_col else usable_cols[0]\n",
    "    return df, filters, title_col, ing_col\n",
    "\n",
    "@st.cache_resource(show_spinner=False)\n",
    "def fit_vectorizer(corpus_texts):\n",
    "    # word n-grams for ingredient matching\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        analyzer=\"word\",\n",
    "        ngram_range=(1,2),\n",
    "        min_df=2,\n",
    "        max_df=0.95\n",
    "    )\n",
    "    X = vectorizer.fit_transform(corpus_texts)\n",
    "    return vectorizer, X\n",
    "\n",
    "def search_similar(query, vectorizer, X, df, title_col, top_k=20, mask=None):\n",
    "    q = normalize_text(query)\n",
    "    q_vec = vectorizer.transform([q])\n",
    "    sims = cosine_similarity(q_vec, X).ravel()\n",
    "\n",
    "    idx = np.arange(len(df))\n",
    "    if mask is not None:\n",
    "        idx = idx[mask]\n",
    "\n",
    "    # argsort descending\n",
    "    top_idx = np.argsort(-sims[idx])[:top_k]\n",
    "    picked = idx[top_idx]\n",
    "    out = df.iloc[picked].copy()\n",
    "    out[\"similarity\"] = sims[picked]\n",
    "    # reorder columns\n",
    "    cols = [c for c in df.columns if c not in [\"__text__\", \"similarity\"]]\n",
    "    out = out[[*cols, \"similarity\"]]\n",
    "    return out\n",
    "\n",
    "def apply_filters(df, filters, selections):\n",
    "    if not selections:\n",
    "        return np.ones(len(df), dtype=bool)\n",
    "    mask = np.ones(len(df), dtype=bool)\n",
    "    for nice_name, col in filters.items():\n",
    "        chosen = selections.get(nice_name)\n",
    "        if chosen:\n",
    "            mask &= df[col].astype(str).str.lower().isin([str(x).lower() for x in chosen])\n",
    "    return mask\n",
    "\n",
    "def boost_by_rating(df, base_scores, rating_cols=(\"rating\",\"ratings\",\"avg_rating\",\"average_rating\",\"stars\")):\n",
    "    # If a known rating column exists, combine with similarity using a soft boost\n",
    "    found = None\n",
    "    for c in df.columns:\n",
    "        if c.lower() in rating_cols:\n",
    "            found = c; break\n",
    "    if not found:\n",
    "        return base_scores\n",
    "    r = pd.to_numeric(df[found], errors=\"coerce\")\n",
    "    r = (r - np.nanmin(r)) / (np.nanmax(r) - np.nanmin(r) + 1e-9)  # 0..1\n",
    "    return 0.85*base_scores + 0.15*r\n",
    "\n",
    "# ------------------------------\n",
    "# UI\n",
    "# ------------------------------\n",
    "st.set_page_config(page_title=\"Indian Food Recommender\", page_icon=\"🍲\", layout=\"wide\")\n",
    "\n",
    "st.title(\"🍲 Indian Food Recommendation System\")\n",
    "st.caption(\"Content-based recommendations using TF-IDF + cosine similarity over ingredients and metadata.\")\n",
    "\n",
    "# Data input\n",
    "st.sidebar.header(\"1) Load dataset\")\n",
    "uploaded = st.sidebar.file_uploader(\"Upload CSV (Indian food dataset)\", type=[\"csv\"])\n",
    "default_path = st.sidebar.text_input(\"...or path to CSV (server file system)\", value=\"C:\\\\Users\\\\Komal\\\\Downloads\\\\indian_food.csv\")\n",
    "use_uploaded = uploaded is not None\n",
    "go = st.sidebar.button(\"Load / Reload\")\n",
    "\n",
    "if 'df' not in st.session_state or go:\n",
    "    try:\n",
    "        if use_uploaded:\n",
    "            df = load_dataframe(uploaded)\n",
    "        else:\n",
    "            if not os.path.exists(default_path):\n",
    "                st.info(\"No file at 'data/indian_food.csv'. Upload a CSV or set a valid path in the sidebar.\")\n",
    "                st.stop()\n",
    "            df = load_dataframe(default_path)\n",
    "\n",
    "        df, filters, title_col, ing_col = build_corpus(df)\n",
    "        vectorizer, X = fit_vectorizer(df[\"__text__\"].tolist())\n",
    "\n",
    "        st.session_state.df = df\n",
    "        st.session_state.filters = filters\n",
    "        st.session_state.title_col = title_col\n",
    "        st.session_state.ing_col = ing_col\n",
    "        st.session_state.vectorizer = vectorizer\n",
    "        st.session_state.X = X\n",
    "    except Exception as e:\n",
    "        st.error(f\"Failed to load dataset: {e}\")\n",
    "        st.stop()\n",
    "\n",
    "df = st.session_state.df\n",
    "filters = st.session_state.filters\n",
    "title_col = st.session_state.title_col\n",
    "ing_col = st.session_state.ing_col\n",
    "vectorizer = st.session_state.vectorizer\n",
    "X = st.session_state.X\n",
    "\n",
    "# Sidebar filters\n",
    "st.sidebar.header(\"2) Filters\")\n",
    "selections = {}\n",
    "for nice_name, col in filters.items():\n",
    "    options = sorted([o for o in df[col].dropna().astype(str).unique() if o != \"\"], key=lambda x: x.lower())\n",
    "    if options:\n",
    "        chosen = st.sidebar.multiselect(f\"{nice_name.capitalize()}\", options=options, default=[])\n",
    "        selections[nice_name] = chosen\n",
    "\n",
    "# Query Controls\n",
    "st.sidebar.header(\"3) Query\")\n",
    "mode = st.sidebar.radio(\"Search by:\", [\"Dish name\", \"Ingredients / free text\"], index=0)\n",
    "\n",
    "if mode == \"Dish name\":\n",
    "    options = df[title_col].dropna().astype(str).unique().tolist()\n",
    "    options = sorted(options, key=lambda x: x.lower())[:5000]  # cap for performance\n",
    "    dish = st.selectbox(\"Select a dish\", options)\n",
    "    query = dish\n",
    "else:\n",
    "    query = st.text_input(\"Enter ingredients or what you're craving\", value=\"paneer, tomato, onion, spices\")\n",
    "\n",
    "top_k = st.sidebar.slider(\"Number of recommendations\", min_value=5, max_value=30, value=10, step=1)\n",
    "\n",
    "# Recommend\n",
    "if st.button(\"Recommend\"):\n",
    "    mask = apply_filters(df, filters, selections)\n",
    "    results = search_similar(query, vectorizer, X, df, title_col, top_k=top_k*3, mask=mask)\n",
    "\n",
    "    # (Optional) boost by ratings if present\n",
    "    if \"similarity\" in results.columns:\n",
    "        boosted = boost_by_rating(results, results[\"similarity\"].values)\n",
    "        results = results.assign(score=boosted).sort_values(\"score\", ascending=False).head(top_k)\n",
    "    else:\n",
    "        results = results.head(top_k)\n",
    "\n",
    "    # Show\n",
    "    st.success(f\"Top {len(results)} recommendations for: **{query}**\")\n",
    "    show_cols = [c for c in results.columns if c not in [\"__text__\", \"score\"]]\n",
    "    st.dataframe(results[show_cols].reset_index(drop=True), use_container_width=True)\n",
    "\n",
    "    # Explainability: show top keywords for query match (simple)\n",
    "    st.subheader(\"Why these? (top terms)\")\n",
    "    try:\n",
    "        # show largest TF-IDF terms in the query vector\n",
    "        q_vec = vectorizer.transform([normalize_text(query)])\n",
    "        feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "        arr = q_vec.toarray()[0]\n",
    "        top_idx = np.argsort(arr)[-15:][::-1]\n",
    "        terms = [feature_names[i] for i in top_idx if arr[i] > 0]\n",
    "        st.write(\", \".join(terms) if terms else \"Terms not available.\")\n",
    "    except Exception:\n",
    "        st.write(\"Terms not available.\")\n",
    "\n",
    "# Peek data\n",
    "with st.expander(\"Preview dataset & detected columns\"):\n",
    "    st.write(f\"Detected title column: `{title_col}`  |  ingredients column: `{ing_col}`\")\n",
    "    st.dataframe(df.head(20), use_container_width=True)\n",
    "\n",
    "st.sidebar.caption(\"Tip: Use filters + ingredient search for best results. If ratings exist, they will be used to slightly boost the ranking.\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a4427-8268-48c0-8896-516ae963f1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45338590-946f-47d9-b424-95a0287f50db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
